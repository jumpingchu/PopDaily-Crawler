{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import time\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總篇數:  5000\n",
      "PGC 文章篇數 219\n",
      "分類 JAPAN 有 29 個連結\n",
      "分類 TRAVEL 有 13 個連結\n",
      "分類 FOOD 有 15 個連結\n",
      "分類 LIFE 有 30 個連結\n",
      "分類 PRESS 有 46 個連結\n",
      "分類 OTHER 有 116 個連結\n",
      "總共 249 個連結\n"
     ]
    }
   ],
   "source": [
    "import PopdailyPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main_crawler(url_list):\n",
    "    article_content = []\n",
    "    counter = 1\n",
    "\n",
    "    for url in url_list:\n",
    "        resp = requests.get(url)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            try:\n",
    "                title = re.search(r'(?<=<title>).+(?=</title>)', resp.text).group()\n",
    "                articleBody = re.search(r'(?<=\"articleBody\":\").+(?=\",\"mainEntityOfPage\")', resp.text).group()\n",
    "                tag = re.findall(r'#(\\w+)', articleBody)\n",
    "                post_date = re.search(r'(?<=dateTime=\")\\d+-\\d+-\\d+(?=T)', resp.text).group()\n",
    "                article_class = re.search(r'(?<=,\"name\":\").+(?=\"},\"publisher\":)', resp.text).group()\n",
    "                \n",
    "                article_content.append({\n",
    "                    '文章日期': post_date,\n",
    "                    '分類': article_class,\n",
    "                    '網址': url,\n",
    "                    '標題': title,\n",
    "                    '內文': articleBody,\n",
    "                    '標籤': ' / '.join(tag)\n",
    "                })\n",
    "                print('成功取得第 %s 篇文章資料' % counter)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('第 %s 篇取得資料失敗: %s' % (counter, url))\n",
    "        else:\n",
    "            print('第 %s 篇連結錯誤: %s' % (counter, url))\n",
    "\n",
    "        if counter % 10 == 0:\n",
    "            delay = random.uniform(1, 5)\n",
    "            print('抓了 %s 篇，休息 %s 秒' % (counter, round(delay, 2)))\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    df = pd.DataFrame(article_content)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_dict = PopdailyPages.urls_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 1.27 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n",
      "成功取得第 14 篇文章資料\n",
      "成功取得第 15 篇文章資料\n",
      "成功取得第 16 篇文章資料\n",
      "成功取得第 17 篇文章資料\n",
      "成功取得第 18 篇文章資料\n",
      "成功取得第 19 篇文章資料\n",
      "成功取得第 20 篇文章資料\n",
      "抓了 20 篇，休息 1.86 秒\n",
      "成功取得第 21 篇文章資料\n",
      "成功取得第 22 篇文章資料\n",
      "成功取得第 23 篇文章資料\n",
      "成功取得第 24 篇文章資料\n",
      "成功取得第 25 篇文章資料\n",
      "成功取得第 26 篇文章資料\n",
      "成功取得第 27 篇文章資料\n",
      "成功取得第 28 篇文章資料\n",
      "成功取得第 29 篇文章資料\n"
     ]
    }
   ],
   "source": [
    "df_japan = main_crawler(urls_dict['japan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 4.52 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n"
     ]
    }
   ],
   "source": [
    "df_travel = main_crawler(urls_dict['travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 1.57 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n",
      "成功取得第 14 篇文章資料\n",
      "成功取得第 15 篇文章資料\n"
     ]
    }
   ],
   "source": [
    "df_food = main_crawler(urls_dict['food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 2.18 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n",
      "成功取得第 14 篇文章資料\n",
      "成功取得第 15 篇文章資料\n",
      "成功取得第 16 篇文章資料\n",
      "成功取得第 17 篇文章資料\n",
      "成功取得第 18 篇文章資料\n",
      "成功取得第 19 篇文章資料\n",
      "成功取得第 20 篇文章資料\n",
      "抓了 20 篇，休息 4.98 秒\n",
      "成功取得第 21 篇文章資料\n",
      "成功取得第 22 篇文章資料\n",
      "成功取得第 23 篇文章資料\n",
      "成功取得第 24 篇文章資料\n",
      "成功取得第 25 篇文章資料\n",
      "成功取得第 26 篇文章資料\n",
      "成功取得第 27 篇文章資料\n",
      "成功取得第 28 篇文章資料\n",
      "成功取得第 29 篇文章資料\n",
      "成功取得第 30 篇文章資料\n",
      "抓了 30 篇，休息 2.81 秒\n"
     ]
    }
   ],
   "source": [
    "df_life = main_crawler(urls_dict['life'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 2.13 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n",
      "成功取得第 14 篇文章資料\n",
      "成功取得第 15 篇文章資料\n",
      "成功取得第 16 篇文章資料\n",
      "成功取得第 17 篇文章資料\n",
      "成功取得第 18 篇文章資料\n",
      "成功取得第 19 篇文章資料\n",
      "成功取得第 20 篇文章資料\n",
      "抓了 20 篇，休息 4.6 秒\n",
      "成功取得第 21 篇文章資料\n",
      "成功取得第 22 篇文章資料\n",
      "成功取得第 23 篇文章資料\n",
      "成功取得第 24 篇文章資料\n",
      "成功取得第 25 篇文章資料\n",
      "成功取得第 26 篇文章資料\n",
      "成功取得第 27 篇文章資料\n",
      "成功取得第 28 篇文章資料\n",
      "成功取得第 29 篇文章資料\n",
      "成功取得第 30 篇文章資料\n",
      "抓了 30 篇，休息 1.67 秒\n",
      "成功取得第 31 篇文章資料\n",
      "成功取得第 32 篇文章資料\n",
      "成功取得第 33 篇文章資料\n",
      "成功取得第 34 篇文章資料\n",
      "成功取得第 35 篇文章資料\n",
      "成功取得第 36 篇文章資料\n",
      "成功取得第 37 篇文章資料\n",
      "成功取得第 38 篇文章資料\n",
      "成功取得第 39 篇文章資料\n",
      "成功取得第 40 篇文章資料\n",
      "抓了 40 篇，休息 3.22 秒\n",
      "成功取得第 41 篇文章資料\n",
      "成功取得第 42 篇文章資料\n",
      "成功取得第 43 篇文章資料\n",
      "成功取得第 44 篇文章資料\n",
      "成功取得第 45 篇文章資料\n",
      "成功取得第 46 篇文章資料\n"
     ]
    }
   ],
   "source": [
    "df_press = main_crawler(urls_dict['press'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功取得第 1 篇文章資料\n",
      "成功取得第 2 篇文章資料\n",
      "成功取得第 3 篇文章資料\n",
      "成功取得第 4 篇文章資料\n",
      "成功取得第 5 篇文章資料\n",
      "成功取得第 6 篇文章資料\n",
      "成功取得第 7 篇文章資料\n",
      "成功取得第 8 篇文章資料\n",
      "成功取得第 9 篇文章資料\n",
      "成功取得第 10 篇文章資料\n",
      "抓了 10 篇，休息 3.75 秒\n",
      "成功取得第 11 篇文章資料\n",
      "成功取得第 12 篇文章資料\n",
      "成功取得第 13 篇文章資料\n",
      "成功取得第 14 篇文章資料\n",
      "成功取得第 15 篇文章資料\n",
      "成功取得第 16 篇文章資料\n",
      "成功取得第 17 篇文章資料\n",
      "成功取得第 18 篇文章資料\n",
      "成功取得第 19 篇文章資料\n",
      "成功取得第 20 篇文章資料\n",
      "抓了 20 篇，休息 4.64 秒\n",
      "成功取得第 21 篇文章資料\n",
      "成功取得第 22 篇文章資料\n",
      "成功取得第 23 篇文章資料\n",
      "成功取得第 24 篇文章資料\n",
      "成功取得第 25 篇文章資料\n",
      "成功取得第 26 篇文章資料\n",
      "成功取得第 27 篇文章資料\n",
      "成功取得第 28 篇文章資料\n",
      "成功取得第 29 篇文章資料\n",
      "成功取得第 30 篇文章資料\n",
      "抓了 30 篇，休息 3.91 秒\n",
      "成功取得第 31 篇文章資料\n",
      "成功取得第 32 篇文章資料\n",
      "成功取得第 33 篇文章資料\n",
      "成功取得第 34 篇文章資料\n",
      "成功取得第 35 篇文章資料\n",
      "成功取得第 36 篇文章資料\n",
      "成功取得第 37 篇文章資料\n",
      "成功取得第 38 篇文章資料\n",
      "成功取得第 39 篇文章資料\n",
      "成功取得第 40 篇文章資料\n",
      "抓了 40 篇，休息 3.18 秒\n",
      "成功取得第 41 篇文章資料\n",
      "成功取得第 42 篇文章資料\n",
      "成功取得第 43 篇文章資料\n",
      "成功取得第 44 篇文章資料\n",
      "成功取得第 45 篇文章資料\n",
      "成功取得第 46 篇文章資料\n",
      "成功取得第 47 篇文章資料\n",
      "成功取得第 48 篇文章資料\n",
      "成功取得第 49 篇文章資料\n",
      "成功取得第 50 篇文章資料\n",
      "抓了 50 篇，休息 2.31 秒\n",
      "成功取得第 51 篇文章資料\n",
      "成功取得第 52 篇文章資料\n",
      "成功取得第 53 篇文章資料\n",
      "成功取得第 54 篇文章資料\n",
      "成功取得第 55 篇文章資料\n",
      "成功取得第 56 篇文章資料\n",
      "成功取得第 57 篇文章資料\n",
      "成功取得第 58 篇文章資料\n",
      "成功取得第 59 篇文章資料\n",
      "成功取得第 60 篇文章資料\n",
      "抓了 60 篇，休息 4.87 秒\n",
      "成功取得第 61 篇文章資料\n",
      "成功取得第 62 篇文章資料\n",
      "成功取得第 63 篇文章資料\n",
      "成功取得第 64 篇文章資料\n",
      "成功取得第 65 篇文章資料\n",
      "成功取得第 66 篇文章資料\n",
      "成功取得第 67 篇文章資料\n",
      "成功取得第 68 篇文章資料\n",
      "成功取得第 69 篇文章資料\n",
      "成功取得第 70 篇文章資料\n",
      "抓了 70 篇，休息 4.6 秒\n",
      "成功取得第 71 篇文章資料\n",
      "成功取得第 72 篇文章資料\n",
      "成功取得第 73 篇文章資料\n",
      "成功取得第 74 篇文章資料\n",
      "成功取得第 75 篇文章資料\n",
      "成功取得第 76 篇文章資料\n",
      "成功取得第 77 篇文章資料\n",
      "成功取得第 78 篇文章資料\n",
      "成功取得第 79 篇文章資料\n",
      "成功取得第 80 篇文章資料\n",
      "抓了 80 篇，休息 3.34 秒\n",
      "成功取得第 81 篇文章資料\n",
      "成功取得第 82 篇文章資料\n",
      "成功取得第 83 篇文章資料\n",
      "成功取得第 84 篇文章資料\n",
      "成功取得第 85 篇文章資料\n",
      "成功取得第 86 篇文章資料\n",
      "成功取得第 87 篇文章資料\n",
      "成功取得第 88 篇文章資料\n",
      "成功取得第 89 篇文章資料\n",
      "成功取得第 90 篇文章資料\n",
      "抓了 90 篇，休息 3.68 秒\n",
      "成功取得第 91 篇文章資料\n",
      "成功取得第 92 篇文章資料\n",
      "成功取得第 93 篇文章資料\n",
      "成功取得第 94 篇文章資料\n",
      "成功取得第 95 篇文章資料\n",
      "成功取得第 96 篇文章資料\n",
      "成功取得第 97 篇文章資料\n",
      "成功取得第 98 篇文章資料\n",
      "成功取得第 99 篇文章資料\n",
      "成功取得第 100 篇文章資料\n",
      "抓了 100 篇，休息 4.86 秒\n",
      "成功取得第 101 篇文章資料\n",
      "成功取得第 102 篇文章資料\n",
      "成功取得第 103 篇文章資料\n",
      "成功取得第 104 篇文章資料\n",
      "成功取得第 105 篇文章資料\n",
      "成功取得第 106 篇文章資料\n",
      "成功取得第 107 篇文章資料\n",
      "成功取得第 108 篇文章資料\n",
      "成功取得第 109 篇文章資料\n",
      "成功取得第 110 篇文章資料\n",
      "抓了 110 篇，休息 3.67 秒\n",
      "成功取得第 111 篇文章資料\n",
      "成功取得第 112 篇文章資料\n",
      "成功取得第 113 篇文章資料\n",
      "成功取得第 114 篇文章資料\n",
      "成功取得第 115 篇文章資料\n",
      "成功取得第 116 篇文章資料\n"
     ]
    }
   ],
   "source": [
    "df_other = main_crawler(urls_dict['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('popdaily_pgc.xlsx') as writer:\n",
    "    df_japan.to_excel(writer, sheet_name='日本')\n",
    "    df_travel.to_excel(writer, sheet_name='打卡')\n",
    "    df_life.to_excel(writer, sheet_name='生活')\n",
    "    df_food.to_excel(writer, sheet_name='發胖', engine='xlsxwriter')\n",
    "    df_press.to_excel(writer, sheet_name='波波報')\n",
    "    df_other.to_excel(writer, sheet_name='其他分類')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topTags(df_tag_column):\n",
    "    tags = []\n",
    "    for i in df_tag_column:\n",
    "        tag = i.split(' / ')\n",
    "        tags += tag\n",
    "    freq_tag = Counter(tags)\n",
    "    top_20 = freq_tag.most_common(20)\n",
    "    return top_20    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_japan = get_topTags(df_japan['標籤'])\n",
    "top_20_travel = get_topTags(df_travel['標籤'])\n",
    "top_20_life = get_topTags(df_life['標籤'])\n",
    "top_20_food = get_topTags(df_food['標籤'])\n",
    "top_20_press = get_topTags(df_press['標籤'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 13),\n",
       " ('生活精選', 2),\n",
       " ('聖誕節', 2),\n",
       " ('影劇音樂', 2),\n",
       " ('711', 2),\n",
       " ('一日茶事', 1),\n",
       " ('一日茶事祝福島', 1),\n",
       " ('台灣特有茶', 1),\n",
       " ('台灣茶', 1),\n",
       " ('OOTD穿搭配件類是粉絲心TOP1', 1),\n",
       " ('P助', 1),\n",
       " ('中友百貨', 1),\n",
       " ('卡納赫拉', 1),\n",
       " ('卡納赫拉P助', 1),\n",
       " ('卡納赫拉的小動物們', 1),\n",
       " ('卡納赫拉粉紅兔兔', 1),\n",
       " ('台中中友', 1),\n",
       " ('療癒', 1),\n",
       " ('粉紅兔兔', 1),\n",
       " ('限定店', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 4),\n",
       " ('三六圓仔店', 1),\n",
       " ('九如商號', 1),\n",
       " ('佳佳甜品', 1),\n",
       " ('八棟圓仔湯', 1),\n",
       " ('冬天美食', 1),\n",
       " ('台北湯圓', 1),\n",
       " ('台北美食', 1),\n",
       " ('客家自製湯圓', 1),\n",
       " ('御品元冰火湯圓', 1),\n",
       " ('政江號', 1),\n",
       " ('施家鮮肉湯圓', 1),\n",
       " ('湯圓', 1),\n",
       " ('燕山湯圓', 1),\n",
       " ('百葉溫州餛飩', 1),\n",
       " ('臺一牛奶大王', 1),\n",
       " ('蘇媽媽湯圓', 1),\n",
       " ('雙連圓仔湯', 1),\n",
       " ('A宰羊羊肉專賣店', 1),\n",
       " ('下港吔羊肉專賣店', 1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('生活精選', 21),\n",
       " ('影劇音樂', 12),\n",
       " ('波波名人', 7),\n",
       " ('', 5),\n",
       " ('MM老師', 4),\n",
       " ('Jenny', 3),\n",
       " ('禾浩辰', 3),\n",
       " ('3C少女', 2),\n",
       " ('劉冠廷', 2),\n",
       " ('2021台劇', 2),\n",
       " ('張軒睿', 2),\n",
       " ('蔡凡熙', 2),\n",
       " ('邵雨薇', 2),\n",
       " ('2020影集', 2),\n",
       " ('2020台劇', 2),\n",
       " ('六人行', 1),\n",
       " ('冰與火之歌', 1),\n",
       " ('實習醫生', 1),\n",
       " ('摩登家庭', 1),\n",
       " ('犯罪心理', 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jessieeee', 6),\n",
       " ('跨年景點', 3),\n",
       " ('Munna', 2),\n",
       " ('波波打卡', 2),\n",
       " ('ig打卡', 1),\n",
       " ('偽出國新地標', 1),\n",
       " ('台南官田遊客中心後花園', 1),\n",
       " ('台南必去', 1),\n",
       " ('台南旅遊', 1),\n",
       " ('台南景點', 1),\n",
       " ('西拉雅風景區', 1),\n",
       " ('2021臺北最High新年城', 1),\n",
       " ('Morton', 1),\n",
       " ('仙跡岩親山步道', 1),\n",
       " ('台北莫爾頓牛排館', 1),\n",
       " ('台北跨年', 1),\n",
       " ('四四南村', 1),\n",
       " ('國父紀念館翠湖', 1),\n",
       " ('天籟渡假酒店', 1),\n",
       " ('生活在他方', 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('生活娛樂', 10),\n",
       " ('Kokoro', 8),\n",
       " ('日本娛樂', 4),\n",
       " ('日本', 4),\n",
       " ('038', 4),\n",
       " ('日本演藝圈', 3),\n",
       " ('日本愛好者', 3),\n",
       " ('tina0123', 3),\n",
       " ('日本電影', 3),\n",
       " ('日劇', 3),\n",
       " ('如果30歲還是處男', 3),\n",
       " ('哆啦A夢', 3),\n",
       " ('戀愛可以持續到天長地久', 2),\n",
       " ('傑尼斯', 2),\n",
       " ('愛情故事', 2),\n",
       " ('瘋狂假面', 2),\n",
       " ('小栗旬', 2),\n",
       " ('我是大哥大', 2),\n",
       " ('日本日劇', 2),\n",
       " ('聖哥傳', 2)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
